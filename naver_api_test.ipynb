{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naver API Key 가져오기\n",
    "with open('naver_api_key.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    client_id = lines[0].strip()\n",
    "    client_secret = lines[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장한 파일 가져오기\n",
    "kosdaq_day_price_path = './data/day_price/kosdaq'\n",
    "kospi_day_price_path = './data/day_price/kospi'\n",
    "\n",
    "kospi_xlsx_files = glob.glob(os.path.join(kospi_day_price_path, '*.xlsx'))\n",
    "kospi_file_names = [os.path.basename(file) for file in kospi_xlsx_files]\n",
    "\n",
    "kosdaq_xlsx_files = glob.glob(os.path.join(kosdaq_day_price_path, '*.xlsx'))\n",
    "kosdaq_file_names = [os.path.basename(file) for file in kosdaq_xlsx_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-22 19:41:57.289227] Url Request Success\n",
      "100\n",
      "[2024-07-22 19:41:57.439401] Url Request Success\n",
      "100\n",
      "[2024-07-22 19:41:57.538183] Url Request Success\n",
      "9\n",
      "[2024-07-22 19:41:57.621472] Url Request Success\n",
      "전체 검색 : 209 건\n"
     ]
    }
   ],
   "source": [
    "def get_title_keyword(market_list):\n",
    "    market_name = str(market_list)[:-10]\n",
    "    save_path = \"data/news_and_keyword/\" + market_name + \"/\"\n",
    "    for i in range(len(market_list)):\n",
    "        stock_name = market_list[i].replace(\".xlsx\",\"\")\n",
    "        #stock_name = '3S'\n",
    "        node = 'news'  # 크롤링 할 대상\n",
    "        src_text = '[특징주] ' + stock_name\n",
    "        cnt = 0\n",
    "        title_result_list = []\n",
    "        date_result_list = []\n",
    "        keyword_result_list = []\n",
    "        rate_d1_list = []\n",
    "        rate_d5_list = []\n",
    "        rate_d20_list = []\n",
    "\n",
    "        jsonResponse = get_naver_search(node, src_text, 1, 100)  # [CODE 2]\n",
    "        total = jsonResponse['total']\n",
    "\n",
    "        while ((jsonResponse != None) and (jsonResponse['display'] != 0)):\n",
    "            for post in jsonResponse['items']:\n",
    "                cnt += 1\n",
    "                title_result, date_result = get_post_data(post, cnt)  # [CODE 3]\n",
    "                keywords = get_keyword(title_result,stock_name)\n",
    "                rate_d1, rate_d5, rate_d20 = get_rate(market_name, stock_name, date_result)\n",
    "\n",
    "                title_result_list.append(title_result)\n",
    "                date_result_list.append(date_result)\n",
    "                keyword_result_list.append(keywords)\n",
    "                rate_d1_list.append(rate_d1)\n",
    "                rate_d5_list.append(rate_d5)\n",
    "                rate_d20_list.append(rate_d20)\n",
    "\n",
    "            start = jsonResponse['start'] + jsonResponse['display']\n",
    "            print(jsonResponse['display'])\n",
    "            jsonResponse = get_naver_search(node, src_text, start, 100)  # [CODE 2]\n",
    "            \n",
    "        df_news_keyword = pd.DataFrame(list(zip(date_result_list, title_result_list, keyword_result_list)))\n",
    "\n",
    "        df_news_keyword.to_excel(save_path + stock_name + \".xlsx\", index= False)\n",
    "        print('{}, {} / {}, {}, 뉴스 : {} 건'.foramt(market_name, i+1, len(market_list), stock_name, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(kospi_file_names)):\n",
    "    #file_path = './data/day_price_kospi/' + kospi_file_names[i]\n",
    "    stock_name = kospi_file_names[i].replace(\".xlsx\",\"\")\n",
    "    \n",
    "    node = 'news'  # 크롤링 할 대상\n",
    "    src_text = '[특징주] ' + stock_name\n",
    "    cnt = 0\n",
    "    jsonResult = []\n",
    "\n",
    "    jsonResponse = get_naver_search(node, src_text, 1, 100)  # [CODE 2]\n",
    "    total = jsonResponse['total']\n",
    "\n",
    "    while ((jsonResponse != None) and (jsonResponse['display'] != 0)):\n",
    "        for post in jsonResponse['items']:\n",
    "            cnt += 1\n",
    "            get_post_data(post, jsonResult, cnt)  # [CODE 3]\n",
    "\n",
    "        start = jsonResponse['start'] + jsonResponse['display']\n",
    "        print(jsonResponse['display'])\n",
    "        jsonResponse = get_naver_search(node, src_text, start, 100)  # [CODE 2]\n",
    "        \n",
    "\n",
    "    print('전체 검색 : %d 건' % total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CODE 1]\n",
    "def get_request_url(url):\n",
    "    req = urllib.request.Request(url)\n",
    "    req.add_header(\"X-Naver-Client-Id\", client_id)\n",
    "    req.add_header(\"X-Naver-Client-Secret\", client_secret)\n",
    "\n",
    "    try:\n",
    "        response = urllib.request.urlopen(req)\n",
    "        if response.getcode() == 200:\n",
    "            #print(\"[%s] Url Request Success\" % datetime.datetime.now())\n",
    "            return response.read().decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"[%s] Error for URL : %s\" % (datetime.datetime.now(), url))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CODE 2]\n",
    "def get_naver_search(node, srcText, start, display):\n",
    "    base = \"https://openapi.naver.com/v1/search\"\n",
    "    node = \"/%s.json\" % node\n",
    "    parameters = \"?query=%s&start=%s&display=%s\" % (urllib.parse.quote(srcText), start, display)\n",
    "\n",
    "    url = base + node + parameters\n",
    "    responseDecode = get_request_url(url)  # [CODE 1]\n",
    "\n",
    "    if (responseDecode == None):\n",
    "        return None\n",
    "    else:\n",
    "        return json.loads(responseDecode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CODE 3]\n",
    "def get_post_data(stock_name, post):\n",
    "    title_result = \"\"\n",
    "    date_result = \"\"\n",
    "    \n",
    "    title = post['title']\n",
    "\n",
    "    pDate = datetime.datetime.strptime(post['pubDate'], '%a, %d %b %Y %H:%M:%S +0900')\n",
    "    pDate = pDate.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    title = title.repalce(\"<b>\",\"\")\n",
    "    title = title.replace(\"</b>\", \"\")\n",
    "\n",
    "    src_text = \"[특징주] \" + stock_name\n",
    "    src_text2 = \"[특징주]\" + stock_name\n",
    "\n",
    "    if src_text in title or src_text2 in title:\n",
    "        title_result = title\n",
    "        date_result = pDate\n",
    "        \n",
    "    return title_result, date_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keyword(title, stock_name): # 종목명과 기사제목을 받아 키워드를 추출함\n",
    "    # 직접 정의한 한국어 불용어 목록\n",
    "    stop_words = set([\n",
    "        '이', '그', '저', '것', '수', '등', '들', '및', '의', '를', '에', '과', '와', '한', \n",
    "        '하다', '되다', '을', '를', '은', '는', '이', '가', '로', '으로', '에게', '께', '에서',\n",
    "        '이다', '하다', '것', '있다', '되다', '수', '나', '우리', '너', '있다', '이다', '것', '특징주'\n",
    "    ])\n",
    "    \n",
    "    stop_words.add(stock_name) # 불용어 목록에 종목명 추가(기사에 포함된 종목명이 키워드에 걸리지 않기 위해)\n",
    "\n",
    "    words = word_tokenize(title)\n",
    "\n",
    "    filtered_words = [word for word in words if word.isalnum() and word not in stop_words] # 불용어 및 특수문자 제거\n",
    "    word_freq = Counter(filtered_words) # 단어 빈도 계산\n",
    "    keywords = [word for word, freq in word_freq.most_common(5)] # 키워드 추출 (빈도순 상위 5개 단어)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rate(market_name, stock_name, date):\n",
    "    load_path = \"./data/day_price/\" + market_name + \"/\" + stock_name + \".xlsx\"\n",
    "    df_stock_price = pd.read_excel(load_path)\n",
    "    \n",
    "    base_index = df_stock_price.index[df_stock_price[\"Date\"].str.contains(str(date)[0:10])]\n",
    "    base_close = df_stock_price[\"Close\"][base_index]\n",
    "\n",
    "    d1_close = df_stock_price[\"Close\"][base_index + 1]\n",
    "    d5_close = df_stock_price[\"Close\"][base_index + 5]\n",
    "    d20_close = df_stock_price[\"Close\"][base_index + 10]\n",
    "    \n",
    "    rate_d1 = (d1_close - base_close)/base_close * 100\n",
    "    rate_d5 = (d5_close - base_close)/base_close * 100\n",
    "    rate_d20 = (d20_close - base_close)/base_close * 100\n",
    "\n",
    "    return rate_d1, rate_d5, rate_d20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-07-21 17:59:51.919370] Url Request Success\n",
      "100\n",
      "[2024-07-21 17:59:52.074942] Url Request Success\n",
      "100\n",
      "[2024-07-21 17:59:52.220063] Url Request Success\n",
      "45\n",
      "[2024-07-21 17:59:52.307082] Url Request Success\n",
      "전체 검색 : 245 건\n",
      "가져온 데이터 : 245 건\n",
      "[특징주] AJ네트웍스_naver_news.json SAVED\n"
     ]
    }
   ],
   "source": [
    "node = 'news'  # 크롤링 할 대상\n",
    "src_text = '[특징주] ' + stock_name\n",
    "cnt = 0\n",
    "jsonResult = []\n",
    "\n",
    "jsonResponse = get_naver_search(node, src_text, 1, 100)  # [CODE 2]\n",
    "total = jsonResponse['total']\n",
    "\n",
    "while ((jsonResponse != None) and (jsonResponse['display'] != 0)):\n",
    "    for post in jsonResponse['items']:\n",
    "        cnt += 1\n",
    "        get_post_data(post, jsonResult, cnt)  # [CODE 3]\n",
    "\n",
    "    start = jsonResponse['start'] + jsonResponse['display']\n",
    "    print(jsonResponse['display'])\n",
    "    jsonResponse = get_naver_search(node, src_Text, start, 100)  # [CODE 2]\n",
    "    \n",
    "\n",
    "print('전체 검색 : %d 건' % total)\n",
    "\n",
    "\n",
    "#with open('%s_naver_%s.json' % (srcText, node), 'w', encoding='utf8') as outfile:\n",
    "#    jsonFile = json.dumps(jsonResult, indent=4, sort_keys=True, ensure_ascii=False)\n",
    "\n",
    "#    outfile.write(jsonFile)\n",
    "\n",
    "#print(\"가져온 데이터 : %d 건\" % (cnt))\n",
    "#print('%s_naver_%s.json SAVED' % (srcText, node))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
